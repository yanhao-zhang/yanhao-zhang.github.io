<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0059)http://handtracker.mpi-inf.mpg.de/projects/FastHandTracker/ -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Learning Social Relation Traits from Face Images</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="Social relation defines the association, e.g., warm, friendliness, and dominance, between two or more people. Motivated by psychological studies, we investigate if such fine-grained and high-level relation traits can be characterised and quantified from face images in the wild. To address this challenging problem we propose a deep model that learns a rich face representation to capture gender, expression, head pose, and age-related attributes, and then performs pairwise-face reasoning for relation prediction. To learn from heterogeneous attribute sources, we formulate a new network architecture with a bridging layer to leverage the inherent correspondences among these datasets. It can also cope with missing target attribute labels. Extensive experiments show that our approach is effective for fine-grained social relation learning in images and videos.>
<meta name="keywords" content="social relation; face expression; fine-grained social relation; deep learning; Convolutional network; computer vision;">
<link rel="author" href="personal.ie.cuhk.edu.hk/~zz013/">

<!-- Fonts and stuff -->
<link href="./support/css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./support/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./support/iconize.css">
<script async="" src="./support/prettify.js"></script>


</head>

<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
	<h1>Learning Social Relation Traits from Face Images</h1>

	<div class="authors">
	  <a href="http://personal.ie.cuhk.edu.hk/~zz013/">Zhanpeng Zhang</a>&nbsp;&nbsp;
	  <a href="http://personal.ie.cuhk.edu.hk/~pluo/">Ping Luo</a>&nbsp;&nbsp;
	  <a href="http://personal.ie.cuhk.edu.hk/~ccloy/" >Chen Change Loy</a>&nbsp;&nbsp;
	  <a href="http://www.ie.cuhk.edu.hk/people/xotang.shtml">Xiaoou Tang</a>
	</div>

	<div class="affiliations">
	  <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Laboratory, </a>
	  <a href="http://www.ie.cuhk.edu.hk/">Department of Information Engineering, </a>
	  <a href="www.cuhk.edu.hk">The Chinese University of Hong Kong</a>
	</div>

	<div class="venue">International Conference on Computer Vision (<a href="http://pamitc.org/iccv15/" target="_blank">ICCV</a>) 2015, Santiago, Chile</div>
      </div>

      
      <center><img src="./support/index.png" border="0" width="85%"></center>
      <div class="section abstract">
	<h2>Abstract</h2>
	<p>
Social relation defines the association, e.g., warm, friendliness, and dominance, between two or more people. Motivated by psychological studies, we investigate if such fine-grained and high-level relation traits can be characterised and quantified from face images in the wild. To address this challenging problem we propose a deep model that learns a rich face representation to capture gender, expression, head pose, and age-related attributes, and then performs pairwise-face reasoning for relation prediction. To learn from heterogeneous attribute sources, we formulate a new network architecture with a bridging layer to leverage the inherent correspondences among these datasets. It can also cope with missing target attribute labels. Extensive experiments show that our approach is effective for fine-grained social relation learning in images and videos.
	</p>
      </div>
<div class="section downloads">
	<h2>Demo</h2><center>
      	<iframe width="560" height="315" src="https://www.youtube.com/embed/z2_7HclTPuc" frameborder="0" allowfullscreen></iframe>
      </div></center>
      <div class="section downloads">
	<h2>Downloads</h2>
	<center>
	  <ul>
            <li class="grid">
	      <div class="griditem">
		<a href="./support/ICCV15.pdf" target="_blank" class="imageLink"><img src="./support/PDF_thumb.png"></a><br>
		  Paper<br><a href="./support/ICCV15.pdf">PDF, 1.3 MB</a>
		</div>
	      </li>
	    <li class="grid">
	      <div class="griditem">
		<a href="./support/sm.pdf" target="_blank" class="imageLink"><img src="./support/sm.png"></a><br>
		  Supplementary Document<br><a href="./support/sm.pdf" target="_blank">PDF, 1.7 MB</a>
		</div>
	      </li>
	    <li class="grid">
	      <div class="griditem">
		<img src="./support/dataset.png"></a><br>
		  Social Relation Dataset<br>[Coming Soon]
		</div>
	      </li>
	  
	    </ul>
	    </center>
	    </div>
	    


<br>
 <div class="section list">
	<h2>Citation</h2>
	
	<div class="section bibtex">
	  <pre>@inproceedings{SOCIALRELATION_ICCV2015,
 author = {Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang},
 title = {Learning Social Relation Traits from Face Images},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = December,
 year = {2015}
} 
	</pre>
	  </div>
      </div>

     <div class="section contact">
	<h2>Contact</h2>
	Zhanpeng Zhang<br><a href="mailto:zz013@ie.cuhk.edu.hk">zz013@ie.cuhk.edu.hk</a>
      </div>
    </div>
  </div>




</body></html>